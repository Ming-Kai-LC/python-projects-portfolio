{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 09: Advanced Projects\n",
    "\n",
    "**Duration:** 120+ minutes  \n",
    "**Difficulty:** Advanced  \n",
    "**Prerequisites:** All previous modules\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "1. Build complex multi-step workflows\n",
    "2. Implement complete automation systems\n",
    "3. Integrate multiple services\n",
    "4. Apply best practices\n",
    "\n",
    "## Capstone Project 1: Complete ETL Pipeline\n",
    "\n",
    "### Goal\n",
    "Extract data from multiple sources, transform it, load to database, and notify stakeholders.\n",
    "\n",
    "### Workflow Steps\n",
    "\n",
    "1. **Schedule Trigger** (Daily at 2 AM)\n",
    "2. **Extract Data**:\n",
    "   - HTTP Request to API 1\n",
    "   - HTTP Request to API 2\n",
    "   - Read from database\n",
    "3. **Merge Data** (Merge node)\n",
    "4. **Transform**:\n",
    "   - Code node for cleaning\n",
    "   - Set node for formatting\n",
    "   - IF node for validation\n",
    "5. **Load**:\n",
    "   - PostgreSQL node (insert/update)\n",
    "6. **Notify**:\n",
    "   - Email with summary\n",
    "   - Slack notification\n",
    "7. **Error Handling**:\n",
    "   - Error trigger\n",
    "   - Log to file\n",
    "   - Alert administrators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Python equivalent of ETL pipeline\n",
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "def etl_pipeline():\n",
    "    \"\"\"\n",
    "    Complete ETL pipeline example\n",
    "    \"\"\"\n",
    "    print(f\"Starting ETL pipeline at {datetime.now()}\\n\")\n",
    "    \n",
    "    # 1. EXTRACT\n",
    "    print(\"1. Extracting data...\")\n",
    "    try:\n",
    "        # Source 1: API\n",
    "        api_data = requests.get('https://api.example.com/data').json()\n",
    "        \n",
    "        # Source 2: CSV\n",
    "        csv_data = pd.read_csv('data.csv')\n",
    "        \n",
    "        # Source 3: Database\n",
    "        # db_data = pd.read_sql_query(query, connection)\n",
    "        \n",
    "        print(\"   âœ… Extraction complete\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"   âŒ Extraction failed: {e}\")\n",
    "        return\n",
    "    \n",
    "    # 2. TRANSFORM\n",
    "    print(\"2. Transforming data...\")\n",
    "    try:\n",
    "        # Clean data\n",
    "        df = csv_data.copy()\n",
    "        df = df.dropna()  # Remove nulls\n",
    "        df['email'] = df['email'].str.lower()  # Normalize\n",
    "        \n",
    "        # Validate\n",
    "        valid_data = df[df['age'] >= 0]\n",
    "        invalid_data = df[df['age'] < 0]\n",
    "        \n",
    "        print(f\"   Valid records: {len(valid_data)}\")\n",
    "        print(f\"   Invalid records: {len(invalid_data)}\")\n",
    "        print(\"   âœ… Transformation complete\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"   âŒ Transformation failed: {e}\")\n",
    "        return\n",
    "    \n",
    "    # 3. LOAD\n",
    "    print(\"3. Loading data...\")\n",
    "    try:\n",
    "        # Save to database\n",
    "        # valid_data.to_sql('users', connection, if_exists='append')\n",
    "        \n",
    "        # Export for backup\n",
    "        valid_data.to_csv(f'processed_{datetime.now().date()}.csv')\n",
    "        \n",
    "        print(\"   âœ… Load complete\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"   âŒ Load failed: {e}\")\n",
    "        return\n",
    "    \n",
    "    # 4. NOTIFY\n",
    "    print(\"4. Sending notifications...\")\n",
    "    summary = f\"\"\"\n",
    "    ETL Pipeline Summary\n",
    "    ====================\n",
    "    Completed: {datetime.now()}\n",
    "    Records processed: {len(valid_data)}\n",
    "    Records rejected: {len(invalid_data)}\n",
    "    Status: Success\n",
    "    \"\"\"\n",
    "    print(summary)\n",
    "    \n",
    "    # Send email/Slack notification here\n",
    "    print(\"   âœ… Notifications sent\\n\")\n",
    "    \n",
    "    print(\"Pipeline completed successfully!\")\n",
    "\n",
    "# Run ETL pipeline\n",
    "# etl_pipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Capstone Project 2: AI-Powered Workflow\n",
    "\n",
    "### Goal\n",
    "Create an AI assistant that processes incoming requests\n",
    "\n",
    "### Workflow\n",
    "\n",
    "1. **Webhook Trigger** (receive request)\n",
    "2. **AI Processing**:\n",
    "   - OpenAI/Claude node\n",
    "   - Analyze intent\n",
    "   - Generate response\n",
    "3. **Action Router** (Switch node):\n",
    "   - Route 0: Answer question â†’ Return response\n",
    "   - Route 1: Create task â†’ Add to Notion/Trello\n",
    "   - Route 2: Send email â†’ Email node\n",
    "   - Route 3: Other â†’ Human review queue\n",
    "4. **Response** (HTTP Response)\n",
    "5. **Logging** (Database/File)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Capstone Project 3: Social Media Automation\n",
    "\n",
    "### Features\n",
    "\n",
    "1. **Content Scheduling**:\n",
    "   - Read from Google Sheets\n",
    "   - Schedule posts\n",
    "   - Post to multiple platforms\n",
    "\n",
    "2. **Monitoring**:\n",
    "   - Track mentions\n",
    "   - Sentiment analysis\n",
    "   - Alert on negative feedback\n",
    "\n",
    "3. **Engagement**:\n",
    "   - Auto-respond to common questions\n",
    "   - Like/retweet based on keywords\n",
    "   - Queue for human review\n",
    "\n",
    "### Workflow Architecture\n",
    "\n",
    "```\n",
    "Schedule Trigger\n",
    "â”œâ”€â†’ Google Sheets (read content)\n",
    "â”œâ”€â†’ IF (check time to post)\n",
    "â”‚   â”œâ”€â†’ Twitter API (post)\n",
    "â”‚   â”œâ”€â†’ LinkedIn API (post)\n",
    "â”‚   â””â”€â†’ Facebook API (post)\n",
    "â””â”€â†’ Update Sheet (mark as posted)\n",
    "\n",
    "Webhook (mentions)\n",
    "â”œâ”€â†’ AI Sentiment Analysis\n",
    "â”œâ”€â†’ Switch (by sentiment)\n",
    "â”‚   â”œâ”€â†’ Positive: Auto-like + Thank\n",
    "â”‚   â”œâ”€â†’ Neutral: Queue for review\n",
    "â”‚   â””â”€â†’ Negative: Alert + Priority queue\n",
    "â””â”€â†’ Log to Database\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Capstone Project 4: Data Processing System\n",
    "\n",
    "### Goal\n",
    "Process uploaded files and generate reports\n",
    "\n",
    "### Workflow Steps\n",
    "\n",
    "1. **File Upload Trigger** (Webhook with file)\n",
    "2. **Validate File**:\n",
    "   - Check file type\n",
    "   - Verify size\n",
    "   - Scan for malware (optional)\n",
    "3. **Parse File**:\n",
    "   - CSV/Excel parser\n",
    "   - Code node for custom formats\n",
    "4. **Process Data**:\n",
    "   - Clean and validate\n",
    "   - Calculate statistics\n",
    "   - Generate insights\n",
    "5. **Create Report**:\n",
    "   - Format results\n",
    "   - Generate charts (Python)\n",
    "   - Create PDF\n",
    "6. **Distribute**:\n",
    "   - Email report\n",
    "   - Upload to cloud storage\n",
    "   - Notify stakeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Example: Generate report with Python\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from io import BytesIO\n",
    "import base64\n",
    "\n",
    "def generate_data_report(df):\n",
    "    \"\"\"\n",
    "    Generate report from DataFrame\n",
    "    \"\"\"\n",
    "    report = {\n",
    "        'summary': {\n",
    "            'total_records': len(df),\n",
    "            'columns': list(df.columns),\n",
    "            'date_generated': str(datetime.now())\n",
    "        },\n",
    "        'statistics': df.describe().to_dict(),\n",
    "        'missing_values': df.isnull().sum().to_dict()\n",
    "    }\n",
    "    \n",
    "    # Generate chart\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    df.plot(kind='bar')\n",
    "    plt.title('Data Overview')\n",
    "    \n",
    "    # Save to buffer\n",
    "    buffer = BytesIO()\n",
    "    plt.savefig(buffer, format='png')\n",
    "    buffer.seek(0)\n",
    "    \n",
    "    # Encode for embedding\n",
    "    image_base64 = base64.b64encode(buffer.read()).decode()\n",
    "    report['chart'] = image_base64\n",
    "    \n",
    "    return report\n",
    "\n",
    "# Example usage\n",
    "sample_data = pd.DataFrame({\n",
    "    'product': ['A', 'B', 'C'],\n",
    "    'sales': [100, 150, 120]\n",
    "})\n",
    "\n",
    "# report = generate_data_report(sample_data)\n",
    "print(\"Report generation function ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Practices for Complex Workflows\n",
    "\n",
    "### 1. Modularity\n",
    "- Break into sub-workflows\n",
    "- Reuse common patterns\n",
    "- Keep workflows focused\n",
    "\n",
    "### 2. Error Handling\n",
    "- Add error triggers\n",
    "- Implement retry logic\n",
    "- Log all errors\n",
    "- Alert on failures\n",
    "\n",
    "### 3. Testing\n",
    "- Test with sample data\n",
    "- Verify edge cases\n",
    "- Use manual trigger initially\n",
    "- Monitor after activation\n",
    "\n",
    "### 4. Documentation\n",
    "- Add notes to nodes\n",
    "- Document workflow purpose\n",
    "- Keep credentials organized\n",
    "- Version control JSON files\n",
    "\n",
    "### 5. Performance\n",
    "- Minimize API calls\n",
    "- Use batching when possible\n",
    "- Optimize database queries\n",
    "- Consider execution time limits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Challenge: Build Your Own\n",
    "\n",
    "### Task\n",
    "Design and implement a workflow that solves a real problem you have.\n",
    "\n",
    "### Requirements\n",
    "1. Use at least 5 different node types\n",
    "2. Include error handling\n",
    "3. Implement logging\n",
    "4. Add notifications\n",
    "5. Document the workflow\n",
    "6. Export and version control\n",
    "\n",
    "### Ideas\n",
    "- Personal finance tracker\n",
    "- Job application monitor\n",
    "- Newsletter generator\n",
    "- Expense report automation\n",
    "- Content aggregator\n",
    "- Meeting scheduler\n",
    "- Backup automation\n",
    "- API monitoring system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Course Completion! ğŸ‰\n",
    "\n",
    "**You've mastered:**\n",
    "- n8n fundamentals and advanced features\n",
    "- Workflow design and best practices\n",
    "- Python integration and automation\n",
    "- Production deployment strategies\n",
    "- Complex multi-service automation\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. **Build Real Projects**: Apply your knowledge\n",
    "2. **Join Community**: [n8n Community Forum](https://community.n8n.io/)\n",
    "3. **Explore Templates**: [n8n.io/workflows](https://n8n.io/workflows/)\n",
    "4. **Contribute**: Share your workflows\n",
    "5. **Keep Learning**: Explore advanced features\n",
    "\n",
    "### Resources\n",
    "\n",
    "- [n8n Documentation](https://docs.n8n.io/)\n",
    "- [n8n YouTube Channel](https://www.youtube.com/c/n8n-io)\n",
    "- [n8n Blog](https://n8n.io/blog/)\n",
    "- [GitHub Repository](https://github.com/n8n-io/n8n)\n",
    "\n",
    "---\n",
    "\n",
    "**Congratulations on completing the n8n Workflow Automation course!**\n",
    "\n",
    "You're now equipped to build powerful automation systems and integrate them with Python. Keep building, keep automating! ğŸš€"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
